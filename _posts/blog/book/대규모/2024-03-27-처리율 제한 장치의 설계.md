---
title: "[가상 면접 사례로 배우는 대규모 시스템 설계 기초] 4장 처리율 제한 장치의 설계"
publish_date: 2024-03-27T15:11:00
last_modified_at: 2024-03-27
category: 프로그래밍 방법
tags:
  - 설계
  - 가상면접사례로배우는대규모시스템설계기초
  - 책요약
---

[책정보](https://m.yes24.com/Goods/Detail/102819435)
![images](/assets/images/대규모/IMG-20240910172136.png)
### 처리율 제한 장치
클라이언트나 서비스가 보내는 트래픽의 처리율을 제어하기위한장치. HTTP를 예로들면 특정 기간 내 전송되는 클라이언트의 요청횟수를 제한함. api의 요청횟수가 임계치를 넘어서면 추가로 도달한 모든 호출은 block됨
- 토큰 버킷
	- 지정된 용량을 갖는 컨테이너. 이 버킷에 사전 설정된 양의 토큰이 주기적으로 채워짐. 꽉차면 더 이상 추가는 안됨. 용량이 꽉찬 시점에서 추가된 토큰은 버려짐
	- 요청이 처리될때마다 하나의 토큰을 사용
	- 요청 처리를 위한 토큰이 없다면? -> 요청 자체를 버림. 토큰이 다시 차도 버린 요청을 처리하지않음
	- 2개의 인자를 받음
		- 버킷 크기 : 버킷에 담을 수 있는 토큰의 최대 개수
		- 토큰 공급률 : 초당 몇개의 토큰이 버킷에 공급되는가?
	- 장점
		- 구현이 쉬움
		- 메모리 사용측면에서 효율적
		- 짧은 시간에 집중되는 트래픽도 처리 가능
	- 단점
		- 버킷크기와 토큰공급률이라는 두개의 인자를 적절하게 튜닝하는것이 어려움
- 누출 버킷
	- 토큰 버킷과 비슷하나 요청 처리율이 고정되어있음. 보통 FIFO(선입선출)로 구현함
	- 요청이 도착하면 큐가 가득차있는지 확인. 빈자리가 있으면 큐에 요청 추가
	- 큐가 가득 차면 새 요청은 버림
	- 지정된 시간마다 큐에서 요청을 꺼내 처리
	- 2개의 인자를 받음
		- 버킷크기 : 큐사이즈와 같은 값.
		- 처리율 : 지정된 시간동안 몇개의 항목을 처리할건지 지정하는 값
	- 전자 상거래 기업 쇼피파이(shopify)가 사용중인 방법
	- 장점
		- 큐의 크기가 제한되어있어 메모리 사용량 측면에서 효율적
		- 고정된 처리율을 가지고있어 안정적 출력이 필요한경우 적합
	- 단점
		- 단시간에 많은 트래픽이 몰리는 경우 큐에는 오래된 요청들이 쌓이게되고 요청을 처리하지못하면 최신요청은 모두 버려짐
		- 2개의인자를 튜닝하기 까다로움
- 고정 윈도 카운터
	- 타임라인을 고정된 간격의 윈도로 나누고 각 윈도마다 카운터를 붙임
	- 요청이 접수될때마다 카운터의 값이 1씩 증가
	- 카운터값이 사전에설정한 임계치를 넘어서면 새로운 요청 윈도가 열릴때까지 버려짐 
	- 예시
		1. 타임라인을 1초로 잡고, 임계치를 3으로 설정. == 시스템은 1초동안 3개의 요청만 처리함
		2. 매초마다 4번째 요청부터는 모두 버려짐 
	- 장점
		- 메모리의 효율이 좋음
		- 이해하기 쉬움
		- 윈도가 닫히는 시점에 카운터를 초기화하는 방식이라 특정한 트래픽패턴을 처리하기 적합
	- 단점 : <mark class="hltr-cyan">윈도의 경계 부근에 순간적으로 많은 트래픽이 몰리는경우 임계치보다 더 많은 양이 처리될수도있음!!</mark>
	
>[!예시]
>
>분당 임계치가 3개일경우 
>
>1. 2:00:00~2:00:30 1개의 요청
>2. 2:00:30~2:01:00 2개의요청
>3. 2:01:00~2:01:30 2개의 요청
>4. 2:01:30~2:02:00 1개의 요청
>
>2:00:00~2:01:00, 2:01:00~2:02:00 을 기준으로 보면 분당 임계치 3개 내로 처리가됨. 그러나 2:00:30~2:01:30을 기준으로 보게되면 4개가 처리됨!! 
>
>1분동안 3개를 허용했는데 <mark class="hltr-cyan">시간을 어떻게 나누냐에따라 임계치를 넘게 처리되기도함을 알수있음</mark>
>

- 이동 윈도 로그
	- 고정윈도카운터의 문제를 해결하기위해 요청의 타임스탬프를 추적하는 방법
	- 타임스탬프 터는 보통 레디스의 정렬집합같은 캐시에 보관함
	- 새요청이 오면 만료된 타임스탬프는 제거, 만료된 타임 스탬프는 그 값이 현재 윈도 시작 시점보다 오래된 타임 스탬프를 말함
	- 새 요청의 타임스탬프를 로그에 추가
	- 로그의 크기가 허용치보다 크거나 같으면 요청을 시스템에 전달, 아니면 거부
	- 장점 : 매우 정료한 메커니즘으로 요청의 갯수가 시스템 한도를 넘지 않음
	- 거부된 요청의 타임스탬프도 보관하기때문에 다량의 메모리를 사용

> [!예시] 
> 
> 분당 2번의 요청만 허용
> 
> 1. 1:00:01 요청
> 2. 1:00:30 요청 
> 3. 1:00:50 요청 => 거절된 요청
> 4. 1:01:40 요청
> 
> 위와 같이 4번의 요청이 들어왔을때, 요청이 들어온 시간(리눅스 타임스탬프)을 기록함.
> 
> 1, 2번 요청은 첫 요청이라 처리 가능. 3번 요청이 들어왔을때 요청 들어온 시간부터 1분전까지(해당요청이 1:00:50이니 0:59:50까지 조회할거임)몇번의 요청이 들어왔는지 확인, 해당 문제에서는 이미 2번 처리했기때문에 요청 거부.
> 
> 4번요청은 1:00:40~:1:01:40까지의 요청을 조회했을때 조회되는 로그는 3번이있으나 요청 처리된 건이 아니라 무시함! => 4번요청 성공
> 
> 따라서 위의 4번의 요청중 처리거부된 요청은 3번뿐임
> 

- 이동 윈도 카운터
	- 고정윈도 카운터 알고리즘 + 이동윈도로그 알고리즘
	- 두가지 접근법이있으나 책에서는 하나만 소개함
	- 분당 7개의 요청처리가능할때, 직전 1분에 5개, 현재 1분에 3개 요청이 들어왔다 가정. 현재 1분의 30%지점에서 도착한 새 요청의 경우 현재 윈도에 몇개의 요청이왔는가?
	
	  -> 현재 1분간 요청 수 + 직전 1분간 요청 수 * 이동윈도와 직전 1분이 겹치는 비율
	  
	  3 + 5 * 70% = 6.5 (올림, 내림은 상황에따라 다르나 이번 예제에서는 내림으로 계산함)
	  
	  이번 1분동안 총 6개의 요청을 처리했으니 이번 요청도 처리가능(단 같은 시간대로 한번 더 요청이 들어오면 처리거부)
  - 장점
	  - 이전 시간대의 평균 처리율에 따라 현재 윈도상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응
	  - 메모리 효율이 좋음
  - 단점
  
	  - 직전 시간대에 도착한 요청이 균등하게 분포되어있다고 가정한 상태에서 추정치를 계산하기때문에 다소 느슨함.
	  
	    그러나 그리 심각한 문제는 아님! 클라우드플레어가 실시한 실험에 따르면 40억개의 요청 중 시스템의 실제상태와 맞지않게 허용되거나 버려진 요청은 0.003%였음
	    
#### 개략적인 아키텍처

처리율 제한 알고리즘에서 얼마나 많은 요청이 접수되었는지 추적할수있는 카운터를 추적대상별로(사용자별/IP주소별/API엔드포인트별/서비스단위)두는데 이때 <mark class="hltr-cyan">카운터는 어디에 보관할것인가</mark>?

메모리상에서 동작하는 캐시가 바람직할것인데 대표적으로 redis는 처리율 제한 장치를 구현할때 자주사용되는 메모리 기반 저장장치로서, INCR와 EXPIRE 두가지 명령어를 지원함

- INCR : 메모리에 저장된 카운터의 값을 1만큼 증가
- EXPIRE : 카운터에 타임아웃 값을 설정. 설정 시간이 지나면 카운터는 자동 삭제
1. 클라이언트가 처리율 제한 미들웨어에게 요청을 보냄
2. 처리율 제한 미들웨어는 레디스의 지정 버킷에서 카운터를 가져와 한도 도달여부 검사
	- 도달했다면 요청 거부
	- 도달하지않았다면 API서버로 요청 전송 
3. 미들웨어는 카운터의 값을 증가 시킨 후 다시 레디스에 저장
=> 그렇다면 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장되는가?
	리프트(Lyft)는 처리율제한에 오픈소스를 사용함
=> 처리가 제한된 요청은 어떻게 처리되는가?
	한도제한이 걸리면 429응답을 클라에게 보냄

**처리율 제한장치가 사용하는 HTTP헤더**
![image](/assets/images/대규모/IMG-20240910172910.png)
### 분산 환경에서의 처리율 제한 장치의 구현

분산환경에서는 여러대의 서버와 병렬 스레드를 지원하도록 시스템을 확장하는 것이 또다른 문제임

- 경쟁조건(race confition)
	- 처리율 제한 장치의 동작법
		1. 레디스에서 카운터의 값을 읽음
		2. 카운터 + 1이 임계치를 넘는지 확인 -> **<mark class="hltr-cyan">문제발생 지점</mark>**
		3. 넘지않는다면 레디스의 보관된 카운터의 값을 1만큼 증가
	- A요청과 B요청이 연속으로 들어왔을때, A요청의 3번이 처리되지않은상태에서 B요청의 1번이 실행된다면? **<mark class="hltr-cyan">A요청과 B요청의 1번 작업결과는 동일함</mark>**
	- 해결방법
		- LOCK: 가장 대표적인 방법이나 시스템성능을 상당히 떨어뜨린다는 문제가 있음
		- 루아 스크립트
		- 정렬집합(레디스 자료구조)
- 동기화(synchronization)
	- 처리율 제한장치가 2개라면? 둘 사이의 동기화가 제대로 이루어지지 않는다면 올바르게 처리율 제한을 할 수 없을것임
	- 해결방법
		- 고정세션(sticky session): 같은 클라이언트로부터 들어온 요청은 항상 같은 처리율제한장치로 보낼수있도록 하는것이나 확장불가, 유연하지못함으로 추천하지않음.
		- 중앙집중형 데이터 저장소 사용 : 대표적으로 레디스. 처리율 제한장치가 카운터를 읽어올때 레디스에서 읽어온다면 문제가 해결됨
#### 성능 최적화

여러 데이터 센터를 지원하면서 멀리떨어진 사용자를 지원하려하면 지연시간이 증가함.

제한장치간의 데이터를 동기화할때 최종 일관성모델을 사용. -> 6장 키-값 저장소 설계의 데이터 일관성 항목 참조

- 모니터링
	- 처리율 제한장치 설계 후 효과적으로 동작(채택한 처리율제한 알고리즘/규칙이 효과적?)하는지 확인해보기위해 사용
	- 깜짝세일같은 이벤트때문에 트래픽이 급증할때 처리율제한장치가 비효율적이라면 트래픽패턴을 파악해 잘 처리할 수 있도록 알고리즘을 바꾸는 것을 고려

> [!추가적으로 확인하면 좋은 내용]
> 
> - 경성 또는 연성 처리율 제한
> 	- 경성(hard)처리율 제한 : 요청 개수는 임계치를 절대 넘을 수 없음
> 	- 연성(soft)처리율 제한 : 요청 개수가 임계치를 잠시동안은 넘을 수 있음
> - 다양한 계층에서의 처리율 제한
> 	- 책에서는 애플리케이션계층(HTTP: OSI 네트워크 계층도 기준으로 7번)에서의 처리율 제한만 설명했으나 다른계층에서의 제한도 가능함
> 	- 예를들어 Iptables를 사용한다면 IP(3번계층)주소에서 처리율 제한도 가능
> - 처리율 제한 회피
> 	- 클라이언트 측 캐시를 사용해 api호출횟수 감소
> 	- 처리율 제한 임계치를 이해하고 너무 짧은시간동안 너무 많은 메세지를 보내지 말것
> 	- 예외나 에러를 처리하는 코드를 도입해 클라이언트가 예외적 상황으로 우아하게(gracefully) 복구되도록할것
> 	- 재시도 로직을 구현할때는 충분한 백오프(back-off)시간을 두기
